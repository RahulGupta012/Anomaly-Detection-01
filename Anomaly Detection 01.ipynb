{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a736c7d-53eb-4a23-8ef6-75086f544a21",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3498db; color: #fff; padding: 10px; border-radius: 10px; text-align: center;\">Anomaly Detection</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afe57b-f7c6-4b30-9d5c-0a19ca869d00",
   "metadata": {},
   "source": [
    "# Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198899a-1c4e-492a-a909-9cf083cf8e49",
   "metadata": {},
   "source": [
    "Anomaly detection is use for detecting the outliers in a dataset which are important for a problem statment.It helps in discovering errors, outliers, or anomalies that may be indicative of issues in the data or underlying processes.\n",
    "\n",
    "In cybersecurity, anomaly detection is used to identify unusual patterns of behavior that might indicate a security threat or intrusion. For example, detecting abnormal network traffic patterns can help identify potential attacks.\n",
    "\n",
    "Anomaly detection is applied across various domains, including finance, cybersecurity, manufacturing, healthcare, and more. It can be used to detect fraudulent transactions, network intrusions, equipment malfunctions, and health abnormalities, among other things.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69733c1-f192-48b8-849e-40585f85c372",
   "metadata": {},
   "source": [
    "# Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e7a91-d6d2-40a9-8c8f-b5f5bfcaa7b6",
   "metadata": {},
   "source": [
    "Anomaly detection is a usefull technique in the field of data analysis and machine learning as it may performe vary important duty , however there are some challenges , which we may face while using anomaly detection . These are ;\n",
    "\n",
    "- Anomalies can manifest in various ways, including point anomalies, contextual anomalies, and collective anomalies. Different types of anomalies may require different detection approaches.\n",
    "\n",
    "- For imbalanced data set when the the training of data has bised towards the majority class, anomaly detection may challenging.\n",
    "\n",
    "- In the case of outliers, it is hard to find the real anomaly in the noise of outliers.\n",
    "\n",
    "- When we are dealing with high dimensional data, it is hard to find the the most relevent feature in the data for proceeding the anomaly detction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610c8fe-00ed-4c52-bffa-d24627d4a3f3",
   "metadata": {},
   "source": [
    "# Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9d457-4b4a-450b-9ed8-b564c427e440",
   "metadata": {},
   "source": [
    "Unsupervised and supervised anomaly detection both are the different techniques for detecting the outliers which are most important for the problem statment. The differnece between supervised and unsupervised meachine learning is the lables as in unsupervised machine learning there are no lables in the data..ie they don't have any 'y' or output feature while in the supervised meachine learning data has labled with two types of features ie.. dependent and independent feature. In case of anomaly detection they both are a differenet techniques in such aspects :\n",
    "\n",
    "**Training Data :** In unsupervised anomaly detection, the algorithm is trained on a dataset that contains only normal (non-anomalous) instances. In supervised anomaly detection, the algorithm is trained on a dataset that includes both normal and anomalous instances. \n",
    "\n",
    "**Applicability :** Unsupervised methods are particularly useful when anomalies are rare, and it's challenging to obtain labeled examples of anomalies. They are suitable for scenarios where the types of anomalies are not well-defined in advance.Supervised methods are beneficial when labeled examples of anomalies are available and there is a clear understanding of the types of anomalies that need to be detected. They are suitable for scenarios where the anomalies are well-defined and can be explicitly labeled.\n",
    "\n",
    "**Evaluation :**\n",
    "Evaluating the performance of unsupervised methods can be challenging since there are no labeled anomalies in the training data. In supervised method Performance evaluation is more straightforward in supervised methods because labeled anomalies are used during training, and standard metrics such as precision, recall, and F1-score can be employed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bbf74-88a5-4448-9361-90d84965259b",
   "metadata": {},
   "source": [
    "# Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d9a2f-a4ca-4a73-a091-8018e3d4c766",
   "metadata": {},
   "source": [
    "The anomaly detection has been executed by the sevral alorithems of the machine learning, which we had discussed in our previous assigments. Some of the common algorithems which often used for the anomaly detection are following :\n",
    "\n",
    "- Isolation Forest (Decision Tree method) -----> Unsupervised \n",
    "- DBSCAN Clustering \n",
    "- Local Outliers Fcator Anomaly Detection (LOF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccb685-12dc-4683-893b-0221bae3b4ae",
   "metadata": {},
   "source": [
    "# Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92410051-eb5d-41c1-bef3-9b65f3415b23",
   "metadata": {},
   "source": [
    "The main asumption made by the distance-based anomaly detection is that, the normal datapoint and anomalies should be clearly distnigiushed by the distance. Which means the clusters of the normal data and the anomalies should be clear and distinct by the help of distance. Which means anomalies should be isolated from the feature space , where the clusters of normal datapoint are exist.In some cases, distance-based methods assume that the data can be effectively represented in a lower-dimensional space where the distance computations are more meaningful. Techniques such as Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) may be employed to achieve dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d937ba-ee0f-4255-b215-51b2cfbfd4b2",
   "metadata": {},
   "source": [
    "# Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58317b25-718d-4f46-bbad-75fc5f0a4445",
   "metadata": {},
   "source": [
    "Local outlier factor anomaly detection or LOF is used for finding the outliers which are important for a problem statement. LOF has done their anomaly detection by the anomaly score which is the distance between the datapoints. \n",
    "There are two types of outliers in the dataset ; \n",
    "- local Outliers\n",
    "- Global Outliers\n",
    "\n",
    "local outliers which are not so far from the normal clusters or somehow in the range of the clusters however global outliers are very far from the density of the datapoints. LOF has only concern with the local outliers.\n",
    "\n",
    "LOF is using `k-Neighboures technique` to detect the anomalies from the dataset. It first take the value of k as a intial parameter. And by this k value it finds the local density of each datapoint to the k-neighboures and deciding the anomaly as the datapoint, who's local demsity will high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0b617-e1bd-43ab-bd2b-cc61f26795b2",
   "metadata": {},
   "source": [
    "# Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f7696-d3f0-4b8c-86ee-c308333fb1bd",
   "metadata": {},
   "source": [
    "Isolation Forest algorithem is a unsupervised algorithem which is used the descision tree technique to detect the anomlies. Here are the parameters of this algorithem :\n",
    "\n",
    "**n_estimators:**  It controls the number of trees to be built in the ensemble. A higher number of trees can lead to a more robust and accurate model but may increase computation time.\n",
    "\n",
    "**max_samples:**  It determines the subset of data points to be used when constructing each tree. \n",
    "\n",
    "**contamination:**  It is an important parameter as it influences the threshold for classifying instances as anomalies.\n",
    "\n",
    "**max_features:**  It controls the randomness of the splits. A smaller value can increase randomness and diversity among trees but may also lead to less effective splits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392a5f4-97bf-4207-9fdc-a9d7c8812e91",
   "metadata": {},
   "source": [
    "# Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c83e4c-eefa-48fd-9ce8-4ac1c8151fb2",
   "metadata": {},
   "source": [
    "The anomaly score is the distance between the k-neigbioures. and If a data point has only 2 neighbors of the same class within a radius of 0.5, it means that this data point is not close enough to 10 neighbors (K=10). Therefore, the KNN algorithm may not be able to compute a distance to the 10th nearest neighbor for this particular data point.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
